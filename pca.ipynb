{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'machine-learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-4.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m\"\u001b[39;49m\u001b[39mmachine-learning\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'machine-learning'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"machine-learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "from functools import reduce\n",
    "def hdf5(path, data_key = \"data\", target_key = \"target\", flatten = True):\n",
    "    \"\"\"\n",
    "        loads data from hdf5: \n",
    "        - hdf5 should have 'train' and 'test' groups \n",
    "        - each group should have 'data' and 'target' dataset or spcify the key\n",
    "        - flatten means to flatten images N * (C * H * W) as N * D array\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        train = hf.get('train')\n",
    "        X_tr = train.get(data_key)[:]\n",
    "        y_tr = train.get(target_key)[:]\n",
    "        test = hf.get('test')\n",
    "        X_te = test.get(data_key)[:]\n",
    "        y_te = test.get(target_key)[:]\n",
    "        if flatten:\n",
    "            X_tr = X_tr.reshape(X_tr.shape[0], reduce(lambda a, b: a * b, X_tr.shape[1:]))\n",
    "            X_te = X_te.reshape(X_te.shape[0], reduce(lambda a, b: a * b, X_te.shape[1:]))\n",
    "    return X_tr, y_tr, X_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9298\n",
      "9298\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr, X_te, y_te = hdf5(\"machine-learning/usps.h5\")\n",
    "X_tr.shape, X_te.shape\n",
    "#I will choose how to split training and test\n",
    "X_comb=np.append(X_tr,X_te,0)#9298 obs x 256 bits\n",
    "y_comb=np.append(y_tr,y_te)\n",
    "print(len(y_comb))\n",
    "print(len(X_comb[:,1]))\n",
    "print(len(X_comb[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA().fit(X_comb)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.axhline(y=0.9)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95981216"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=100).fit(X_comb)\n",
    "a=np.cumsum(pca.explained_variance_ratio_)\n",
    "a[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Validation:\n",
    "    @staticmethod\n",
    "    def partition(X_train,y_train,k=5):\n",
    "        Xrows = size(X_train[:,1])#6229\n",
    "        Xcols = size(X_train[1,:])#256\n",
    "        print('Xrows ' + str(Xrows) + \" Xcols \" + str(Xcols))\n",
    "        print(\"Add y_train to X_train before shuffling\")\n",
    "        X_copy=np.zeros((Xrows,Xcols+1),dtype=np.float32)\n",
    "        X_copy[:,256] = y_train\n",
    "        X_copy[:,0:256] = X_train\n",
    "        Xcols = size(X_copy[1,:])#256 cols\n",
    "        Xrows = size(X_copy[:,1])#6229 samples rows\n",
    "        print('Xrows ' + str(Xrows) + \" Xcols \" + str(Xcols))#6229x256 --> 6229x 257\n",
    "        #let us append the results else am fucking stuff up\n",
    "        #np.random.shuffle(X_copy) # Shuffle all rows#\n",
    "    \n",
    "        folds = np.array_split(X_copy, k)\n",
    "        length=size(X_copy[1,:])-1\n",
    "#print(size(folds[1][:,1]))#1246 samples\n",
    "#print(size(folds[1][1,:]))#257 cols\n",
    "#ytest = folds[i][:,256]\n",
    "\n",
    "    # some print functions to help you debug\n",
    "    #print(f'Fold {i}')\n",
    "    #print(f'xtest shape  : {xtest.shape}')\n",
    "    #print(f'ytest shape  : {ytest.shape}')\n",
    "    #print(f'xtrain shape : {xtrain.shape}')\n",
    "    #print(f'ytrain  : {ytrain.shape}\\n')\n",
    "        return folds,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "#from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "class KernelPegasos():\n",
    "    # kernels and loss function\n",
    "    ## Kernelised Pegasos with different kernel support:- \"linear\",\"guassian\", \"polynomial\"\n",
    "    def __init__(self,T=10,lamb=1e-3,kernel=\"gaussian\"):\n",
    "        ##lamb --> regularisation param\n",
    "        ## loss_func can be \"hinge loss\" or \"logistic loss\"\n",
    "        self.kernel_list=(\"gaussian\",\"polynomial\", \"linear\")\n",
    "        self.T=T\n",
    "        self.pos_cl = 1\n",
    "        self.neg_cl = -1\n",
    "        self.lamb = lamb\n",
    "\n",
    "\n",
    "        #loss function\n",
    "        #self.loss_func_list=(\"hinge\",\"log\",\"zeroone\")\n",
    "        #if loss_func not in self.loss_func_list:\n",
    "         #   raise Exception(\"Loss function not found!!\\n\")\n",
    "            #hinge\n",
    "        #if loss_func==self.loss_func_list[0]:\n",
    "        #    self.obj = self.update_hinge\n",
    "        #elif loss_func==self.loss_func_list[2]:\n",
    "         #   self.obj = self.update_zeroone\n",
    "        #else:#log\n",
    "         #   self.obj = self.update_log\n",
    "\n",
    "\n",
    "        #kernel \n",
    "        if kernel not in self.kernel_list:\n",
    "            raise Exception(\"Kernel not found!!\\n\")\n",
    "        elif kernel == self.kernel_list[0]:\n",
    "            self.kernel = self.gaussian_kernel\n",
    "        elif kernel ==self.kernel_list[1]:\n",
    "           self.kernel = self.polynomial_kernel\n",
    "        else:\n",
    "           self.kernel = self.linear_kernel\n",
    "            \n",
    "    #Define update functions\n",
    "    def update_hinge(self,score,yi,xi,eta,w):\n",
    "        if yi*score < 1:\n",
    "            return (1 - eta*self.lamb)*w + eta*yi*xi\n",
    "        else:\n",
    "            return (1 - eta*self.lamb)*w\n",
    "\n",
    "    def update_log(self,score,yi,xi,eta,w):\n",
    "        return (1 - eta*self.lamb)*w + xi*eta*yi / (1+expit(yi*score))\n",
    "\n",
    "    def linear_kernel(self,x,y):\n",
    "        return np.dot(x,y)\n",
    "\n",
    "    def polynomial_kernel(self,x, y, p=3):\n",
    "        return (1 + np.dot(x, y)) ** p\n",
    "\n",
    "    def gaussian_kernel(self,x, y, variance=0.25):\n",
    "        #sigma**2 is variance\n",
    "        mean=np.linalg.norm(x-y)**2\n",
    "        return np.exp(-mean / (2 * variance))\n",
    "\n",
    "            \n",
    "    def fit(self,x,y):\n",
    "        ## Complexity :- O(#epoch * #train samples)\n",
    "        try:\n",
    "            x=x.toarray()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        x = np.insert(x,x.shape[1],1,axis=1)\n",
    "        m,n = x.shape[0],x.shape[1] ## m --> number of samples , n --> number of features\n",
    "        self.alpha = np.zeros((self.T+1,m))#iterations,samples\n",
    "        y = list(y)\n",
    "        classes = sorted(set(y))#encode firs \n",
    "        if len(classes) != 2:\n",
    "            raise Exception(\"Not a binary classification!!\\n\")\n",
    "\n",
    "        for t in range(self.T):\n",
    "            step = 1. / (self.lamb*(t+1))\n",
    "            #-- Choose a random xit , yit\n",
    "            it = np.random.randint(0,m)#m is number of samples (lenght y)\n",
    "            #j = self.init_index\n",
    "            xit, yit = x[it], y[it]\n",
    "            #---For all j different than it , set the next alpha[j] to the previous 1\n",
    "            for j in range(m):\n",
    "                if j!=it:\n",
    "                    self.alpha[t+1,j]=self.alpha[t,j]\n",
    "            #Perform the sum over j of the following \n",
    "            sum_=0.0\n",
    "            for j in range(m):\n",
    "                sum_+=self.alpha[t,j]*self.kernel(xit,x[j])*y[j]#alpha weights\n",
    "            sum_*=yit*step\n",
    "            if sum_<1:\n",
    "                self.alpha[t+1,it] = self.alpha[t,it]+1\n",
    "            else:\n",
    "                self.alpha[t+1,it]=self.alpha[t,it]\n",
    "        self.alpha = self.alpha[self.T]\n",
    "        self.y_train = y\n",
    "        self.x_train = x\n",
    "        print(\"fitting Complete!!\\n\")\n",
    "        return self\n",
    "\n",
    "    def predict(self,xtest):\n",
    "        ## complexity O(#support vectors * #test samples)\n",
    "        try:\n",
    "            xtest=xtest.toarray()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        xtest = np.insert(xtest,xtest.shape[1],1,axis=1)\n",
    "        l = xtest.shape[0]#size of ytest\n",
    "        m = self.alpha.shape[0]#size of ytrain\n",
    "        scores = np.zeros(l)\n",
    "        for i in range(l):\n",
    "            score=0.0\n",
    "            for k in range(m):\n",
    "                if self.alpha[k]>0:\n",
    "                    score+=self.alpha[k]*self.kernel(xtest[i],self.x_train[k])*self.y_train[k]\n",
    "            scores[i]=score\n",
    "        ypred = np.select([scores>0.0, scores<=0.0], [self.pos_cl, self.neg_cl])\n",
    "        return ypred#y_pred -1 1 \n",
    "\n",
    "    def score(self,X,y_test):\n",
    "        y_pred= self.predict(X)\n",
    "        errors=0\n",
    "        for i in range(size(y_pred)):\n",
    "            if(y_pred[i]!=y_test[i]):\n",
    "                errors+=1\n",
    "        zerooneloss = errors/len(y_test)        \n",
    "        accuracy =  1- zerooneloss#0-1 mean loss\n",
    "        return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[-1. -1. -1. -1. -1. -1. -1.  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "#one hot encode labels\n",
    "#encoded_labels = []\n",
    "#for i in range(len(y_tr)):\n",
    " # naked = [0,0,0,0,0,0,0,0,0,0]\n",
    "  #naked[y_tr[i]] = 1\n",
    "  #encoded_labels.append(naked)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lr = [0,1,2,3,4,5,6,7,8,9]#from 0 to 9\n",
    "#for label in range(10):\n",
    " #   one_hot = (lr==label).astype(np.int)\n",
    "  #  print(\"label: \", label, \" in one-hot representation: \", one_hot)\n",
    "\n",
    "\n",
    "#We have 7291 numbers. For each number create 9 col.\n",
    "y_combined = np.zeros((y_comb.shape[0], y_comb.max()+1), dtype=np.float32)#7291 rows,9cols\n",
    "#y_train[np.arange(y_tr.shape[0]), y_tr] = 1#7291,0 for each row , set the ytr col ot 1, xth row pops y_tr place 1\n",
    "#ranges from 0->7290 ,0->9\n",
    "y0, y1, y2, y3, y4, y5, y6, y7, y8, y9 = [],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "\n",
    "for row in range(y_comb.shape[0]): #from 0 to 7291 \n",
    "  for col in range(y_comb.max()+1):\n",
    "    if(col == y_comb[row]):\n",
    "      y_combined[row, col] = 1#col range from 0 to 9\n",
    "      eval('y'+str(col)).append(int(1))\n",
    "    else:\n",
    "      y_combined[row, col] = -1\n",
    "      eval('y'+str(col)).append(int(-1))\n",
    "\n",
    "#print(np.arange(y_tr.shape[0]))\n",
    "#print(y_tr)\n",
    "#[-1 if x==0 else x for x in y_train]\n",
    "print(y_comb[3])\n",
    "print(y_combined[3,:])#get row 1 \n",
    "\n",
    "y0 = np.asarray(y0)\n",
    "y1 = np.asarray(y1)\n",
    "y2 = np.asarray(y2)\n",
    "y3 = np.asarray(y3)\n",
    "y4 = np.asarray(y4)\n",
    "y5 = np.asarray(y5)\n",
    "y6 = np.asarray(y6)\n",
    "y7 = np.asarray(y7)\n",
    "y8 = np.asarray(y8)\n",
    "y9 = np.asarray(y9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_comb,currentLabel,test_size=0.33,random_state=42)\n",
    "def non_shuffling_train_test_split(X, y, test_size=0.2):\n",
    "    i = int((1 - test_size) * X.shape[0]) \n",
    "    X_train, X_test = np.split(X, [i])\n",
    "    y_train, y_test = np.split(y, [i])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_pred,y_test):\n",
    "    tp,tn,fp,fn=0,0,0,0\n",
    "    for i in range(size(y_pred)):\n",
    "        if(y_pred[i]==y_test[i]):\n",
    "            if(y_test[i]==-1):#negative\n",
    "                tn+=1\n",
    "            else:\n",
    "                tp+=1                \n",
    "        elif(y_pred[i]!=y_test[i]):\n",
    "            if(y_test[i]==-1):#negative\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        #accuracy is 1-zerooneloss\n",
    "    if((tp+fp)==0):\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=tp/(tp+fp)#best for large sample neg -- p detect positive values -- total pred pos\n",
    "        ##if i get positive-pred --> almost sure it will be\n",
    "        ##if 0 --> all have been recognized as negative !!\n",
    "    if((tn+fn)==0):\n",
    "        fnratio = 0\n",
    "    else:\n",
    "        fnratio=fn/(tn+fn)\n",
    "        ##\n",
    "    if((tp+fn)==0):##no positive cases in input data\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=tp/(tp+fn)\n",
    "    \n",
    "    if(((2*tp+fp+fn))==0):\n",
    "        f1score=0\n",
    "    else:\n",
    "        f1score=2*tp/(2*tp+fp+fn)#all have been rec as engative\n",
    "    if((tp+fp)+(tn+fn)==0):\n",
    "        zerooneloss=0\n",
    "    else:\n",
    "        zerooneloss=(fp+fn)/(tp+fp+tn+fn)#or sum of errors/len(y_test)\n",
    "    #tp+tn\n",
    "    accuracy = 1-zerooneloss\n",
    "    print(\"FN ratio: \", fnratio,\"(\",np.round(fnratio*100, 2),\"%)\")\n",
    "    print(\"FP ratio: \", 1-precision,\"(\",np.round((1-precision)*100, 2),\"%)\")\n",
    "    print(\"Precision: \", precision,\"(\",np.round(precision*100, 2),\"%)\")\n",
    "    print(\"Recall: \", recall,\"(\",np.round(recall*100, 2),\"%)\")\n",
    "    print(\"Accuracy: \", accuracy,\"(\",np.round(accuracy*100, 2),\"%)\")\n",
    "    print(\"f1score: \", f1score,\"(\",np.round(f1score*100, 2),\"%)\")\n",
    "    return precision,f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 diim\n",
    "pca=PCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------y0-------------------\n",
      "Xrows 6229 Xcols 256\n",
      "Add y_train to X_train before shuffling\n",
      "Xrows 6229 Xcols 257\n",
      "Performing 5-Fold validation\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.2030497592295345 ( 20.3 %)\n",
      "FP ratio:  1 ( 100 %)\n",
      "Precision:  0 ( 0 %)\n",
      "Recall:  0.0 ( 0.0 %)\n",
      "Accuracy:  0.7969502407704655 ( 79.7 %)\n",
      "f1score:  0.0 ( 0.0 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.06470028544243578 ( 6.47 %)\n",
      "FP ratio:  0.15897435897435896 ( 15.9 %)\n",
      "Precision:  0.841025641025641 ( 84.1 %)\n",
      "Recall:  0.7068965517241379 ( 70.69 %)\n",
      "Accuracy:  0.920545746388443 ( 92.05 %)\n",
      "f1score:  0.7681498829039812 ( 76.81 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.05170821791320406 ( 5.17 %)\n",
      "FP ratio:  0.3926380368098159 ( 39.26 %)\n",
      "Precision:  0.6073619631901841 ( 60.74 %)\n",
      "Recall:  0.6387096774193548 ( 63.87 %)\n",
      "Accuracy:  0.9036918138041734 ( 90.37 %)\n",
      "f1score:  0.6226415094339622 ( 62.26 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.044605809128630707 ( 4.46 %)\n",
      "FP ratio:  0.4219858156028369 ( 42.2 %)\n",
      "Precision:  0.5780141843971631 ( 57.8 %)\n",
      "Recall:  0.7912621359223301 ( 79.13 %)\n",
      "Accuracy:  0.869983948635634 ( 87.0 %)\n",
      "f1score:  0.6680327868852459 ( 66.8 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.012725344644750796 ( 1.27 %)\n",
      "FP ratio:  0.4635761589403974 ( 46.36 %)\n",
      "Precision:  0.5364238410596026 ( 53.64 %)\n",
      "Recall:  0.9310344827586207 ( 93.1 %)\n",
      "Accuracy:  0.8779116465863454 ( 87.79 %)\n",
      "f1score:  0.680672268907563 ( 68.07 %)\n",
      "Print row 0 For number = 0 with T=10 and lambda=1e-05 avg_acc=0.8738166792370121 av_precision=0.5125651259345181 avg_f1_score=0.5478992896261505 time 22.65246081352234\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.14285714285714285 ( 14.29 %)\n",
      "FP ratio:  0.4744897959183674 ( 47.45 %)\n",
      "Precision:  0.5255102040816326 ( 52.55 %)\n",
      "Recall:  0.40711462450592883 ( 40.71 %)\n",
      "Accuracy:  0.804975922953451 ( 80.5 %)\n",
      "f1score:  0.45879732739420936 ( 45.88 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.044573643410852716 ( 4.46 %)\n",
      "FP ratio:  0.13084112149532712 ( 13.08 %)\n",
      "Precision:  0.8691588785046729 ( 86.92 %)\n",
      "Recall:  0.8017241379310345 ( 80.17 %)\n",
      "Accuracy:  0.9406099518459069 ( 94.06 %)\n",
      "f1score:  0.8340807174887892 ( 83.41 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.023032629558541268 ( 2.3 %)\n",
      "FP ratio:  0.3578431372549019 ( 35.78 %)\n",
      "Precision:  0.6421568627450981 ( 64.22 %)\n",
      "Recall:  0.8451612903225807 ( 84.52 %)\n",
      "Accuracy:  0.9221508828250401 ( 92.22 %)\n",
      "f1score:  0.7298050139275766 ( 72.98 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.06859205776173286 ( 6.86 %)\n",
      "FP ratio:  0.05797101449275366 ( 5.8 %)\n",
      "Precision:  0.9420289855072463 ( 94.2 %)\n",
      "Recall:  0.6310679611650486 ( 63.11 %)\n",
      "Accuracy:  0.9325842696629214 ( 93.26 %)\n",
      "f1score:  0.7558139534883721 ( 75.58 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.015655577299412915 ( 1.57 %)\n",
      "FP ratio:  0.29147982062780264 ( 29.15 %)\n",
      "Precision:  0.7085201793721974 ( 70.85 %)\n",
      "Recall:  0.9080459770114943 ( 90.8 %)\n",
      "Accuracy:  0.9349397590361446 ( 93.49 %)\n",
      "f1score:  0.7959697732997482 ( 79.6 %)\n",
      "Print row 1 For number = 0 with T=10 and lambda=0.0001 avg_acc=0.9070521572646928 av_precision=0.7374750220421694 avg_f1_score=0.7148933571197391 time 22.273633003234863\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.007194244604316547 ( 0.72 %)\n",
      "FP ratio:  0.09890109890109888 ( 9.89 %)\n",
      "Precision:  0.9010989010989011 ( 90.11 %)\n",
      "Recall:  0.9723320158102767 ( 97.23 %)\n",
      "Accuracy:  0.9727126805778491 ( 97.27 %)\n",
      "f1score:  0.935361216730038 ( 93.54 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.0050916496945010185 ( 0.51 %)\n",
      "FP ratio:  0.14015151515151514 ( 14.02 %)\n",
      "Precision:  0.8598484848484849 ( 85.98 %)\n",
      "Recall:  0.978448275862069 ( 97.84 %)\n",
      "Accuracy:  0.9662921348314607 ( 96.63 %)\n",
      "f1score:  0.9153225806451613 ( 91.53 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.0028735632183908046 ( 0.29 %)\n",
      "FP ratio:  0.24752475247524752 ( 24.75 %)\n",
      "Precision:  0.7524752475247525 ( 75.25 %)\n",
      "Recall:  0.9806451612903225 ( 98.06 %)\n",
      "Accuracy:  0.9574638844301766 ( 95.75 %)\n",
      "f1score:  0.8515406162464986 ( 85.15 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.004916420845624385 ( 0.49 %)\n",
      "FP ratio:  0.12227074235807855 ( 12.23 %)\n",
      "Precision:  0.8777292576419214 ( 87.77 %)\n",
      "Recall:  0.9757281553398058 ( 97.57 %)\n",
      "Accuracy:  0.9735152487961477 ( 97.35 %)\n",
      "f1score:  0.9241379310344827 ( 92.41 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.013120899718837863 ( 1.31 %)\n",
      "FP ratio:  0.101123595505618 ( 10.11 %)\n",
      "Precision:  0.898876404494382 ( 89.89 %)\n",
      "Recall:  0.9195402298850575 ( 91.95 %)\n",
      "Accuracy:  0.97429718875502 ( 97.43 %)\n",
      "f1score:  0.9090909090909091 ( 90.91 %)\n",
      "Print row 2 For number = 0 with T=100 and lambda=1e-05 avg_acc=0.9688562274781308 av_precision=0.8580056591216885 avg_f1_score=0.9070906507494179 time 91.46961855888367\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.00819672131147541 ( 0.82 %)\n",
      "FP ratio:  0.09259259259259256 ( 9.26 %)\n",
      "Precision:  0.9074074074074074 ( 90.74 %)\n",
      "Recall:  0.9683794466403162 ( 96.84 %)\n",
      "Accuracy:  0.9735152487961477 ( 97.35 %)\n",
      "f1score:  0.9369024856596558 ( 93.69 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.009813542688910697 ( 0.98 %)\n",
      "FP ratio:  0.022026431718061623 ( 2.2 %)\n",
      "Precision:  0.9779735682819384 ( 97.8 %)\n",
      "Recall:  0.9568965517241379 ( 95.69 %)\n",
      "Accuracy:  0.9879614767255217 ( 98.8 %)\n",
      "f1score:  0.9673202614379085 ( 96.73 %)\n",
      "fitting Complete!!\n",
      "\n",
      "FN ratio:  0.02085222121486854 ( 2.09 %)\n",
      "FP ratio:  0.07692307692307687 ( 7.69 %)\n",
      "Precision:  0.9230769230769231 ( 92.31 %)\n",
      "Recall:  0.8516129032258064 ( 85.16 %)\n",
      "Accuracy:  0.9727126805778491 ( 97.27 %)\n",
      "f1score:  0.8859060402684564 ( 88.59 %)\n",
      "fitting Complete!!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-4.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000009untitled?line=57'>58</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()     \n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000009untitled?line=58'>59</a>\u001b[0m svc\u001b[39m.\u001b[39mfit(xfinsubtrain, ysubtrain)\n\u001b[1;32m---> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000009untitled?line=59'>60</a>\u001b[0m acc_scores[col3no] \u001b[39m=\u001b[39m svc\u001b[39m.\u001b[39;49mscore(pca\u001b[39m.\u001b[39;49mtransform(xsubtest), ysubtest)\u001b[39m#vector 5 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000009untitled?line=60'>61</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000009untitled?line=61'>62</a>\u001b[0m precision,f1score\u001b[39m=\u001b[39mmetrics(svc\u001b[39m.\u001b[39mpredict(pca\u001b[39m.\u001b[39mtransform(xsubtest)),ysubtest)\u001b[39m#precision f1score\u001b[39;00m\n",
      "\u001b[1;32mUntitled-4.ipynb Cell 7'\u001b[0m in \u001b[0;36mKernelPegasos.score\u001b[1;34m(self, X, y_test)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=119'>120</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m,X,y_test):\n\u001b[1;32m--> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=120'>121</a>\u001b[0m     y_pred\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=121'>122</a>\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=122'>123</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(size(y_pred)):\n",
      "\u001b[1;32mUntitled-4.ipynb Cell 7'\u001b[0m in \u001b[0;36mKernelPegasos.predict\u001b[1;34m(self, xtest)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=112'>113</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=113'>114</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha[k]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=114'>115</a>\u001b[0m             score\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha[k]\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(xtest[i],\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train[k])\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train[k]\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=115'>116</a>\u001b[0m     scores[i]\u001b[39m=\u001b[39mscore\n\u001b[0;32m    <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=116'>117</a>\u001b[0m ypred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mselect([scores\u001b[39m>\u001b[39m\u001b[39m0.0\u001b[39m, scores\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_cl, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneg_cl])\n",
      "\u001b[1;32mUntitled-4.ipynb Cell 7'\u001b[0m in \u001b[0;36mKernelPegasos.gaussian_kernel\u001b[1;34m(self, x, y, variance)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgaussian_kernel\u001b[39m(\u001b[39mself\u001b[39m,x, y, variance\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=56'>57</a>\u001b[0m     \u001b[39m#sigma**2 is variance\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=57'>58</a>\u001b[0m     mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x\u001b[39m-\u001b[39;49my)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-4.ipynb?jupyter-notebook#ch0000006untitled?line=58'>59</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mmean \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m variance))\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\linalg\\linalg.py:2530\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/giuli/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/numpy/linalg/linalg.py?line=2527'>2528</a>\u001b[0m     sqnorm \u001b[39m=\u001b[39m dot(x\u001b[39m.\u001b[39mreal, x\u001b[39m.\u001b[39mreal) \u001b[39m+\u001b[39m dot(x\u001b[39m.\u001b[39mimag, x\u001b[39m.\u001b[39mimag)\n\u001b[0;32m   <a href='file:///c%3A/Users/giuli/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/numpy/linalg/linalg.py?line=2528'>2529</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/giuli/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/numpy/linalg/linalg.py?line=2529'>2530</a>\u001b[0m     sqnorm \u001b[39m=\u001b[39m dot(x, x)\n\u001b[0;32m   <a href='file:///c%3A/Users/giuli/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/numpy/linalg/linalg.py?line=2530'>2531</a>\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   <a href='file:///c%3A/Users/giuli/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/numpy/linalg/linalg.py?line=2531'>2532</a>\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Do a big loop 0->9 FINAL\n",
    "#80 rows -- around 4h30\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "#count=-1\n",
    "cv=5\n",
    "count=-1\n",
    "\n",
    "lim_num_classes=10\n",
    "# Choose hyperparams\n",
    "#ite=[10]\n",
    "#lmdb=[1e-5,1e-4]\n",
    "ite = [10,100,1000,1500]\n",
    "lmdb=[1e-5,1e-4]\n",
    "#4x3x10=120\n",
    "rows = size(ite)*size(lmdb)*lim_num_classes\n",
    "results = np.zeros((rows , 2+3+1+1)) # 3 (2 hyper+acc+prec+f1+time+testlabel)* number of ite\n",
    "precision_scores = np.zeros(cv)\n",
    "f1_scores = np.zeros(cv)\n",
    "acc_scores=np.zeros(cv)\n",
    "\n",
    "for j in range (0,lim_num_classes):\n",
    "    currentLabel=eval('y'+str(j)) #this is label i -- have \n",
    "    print(\"-------------\" + 'y' + str(j) +\"-------------------\" )\n",
    "    #Split in train test\n",
    "    X_train, X_test, y_train, y_test = non_shuffling_train_test_split(X_comb,currentLabel,test_size=0.33)\n",
    "\n",
    "#k_fold = KFold(n_splits=5)\n",
    "    folds,length= Cross_Validation.partition(X_train,y_train,k=cv)\n",
    "#folds,length= Cross_Validation.partition(X_comb,currentLabel,k=cv)\n",
    "\n",
    "    print('Performing ' + str(cv) + '-Fold validation')\n",
    "    col1no=-1\n",
    "\n",
    "    for t in ite:\n",
    "        col1no+=1\n",
    "        col2no=-1\n",
    "        for lm in lmdb:\n",
    "                col2no+=1\n",
    "                col3no=-1\n",
    "                scores = np.zeros(cv)   #5 times cross val\n",
    "                count+=1\n",
    "                elaspedt=0\n",
    "#        for id_train, id_test in k_fold.split(X_train):    \n",
    "                for kth in range (cv):\n",
    "                    xsubtest = folds[kth][:,:length] # Set ith fold to be test\n",
    "                    ysubtest = folds[kth][:,length]\n",
    "                    new_folds = np.row_stack(np.delete(folds,kth,0))\n",
    "                    xsubtrain = new_folds[:,:length]\n",
    "                    xfinsubtrain=pca.fit_transform(xsubtrain)\n",
    "                    ysubtrain = new_folds[:,length]\n",
    "                    col3no += 1\n",
    "                    svc = KernelPegasos(T=t, lamb=lm)\n",
    "            #xsubtrain, ysubtrain = X_train[id_train], y_train[id_train]\n",
    "            #xsubtest, ysubtest = X_train[id_test], y_train[id_test]\n",
    "                    start = time.time()     \n",
    "                    svc.fit(xfinsubtrain, ysubtrain)\n",
    "                    acc_scores[col3no] = svc.score(pca.transform(xsubtest), ysubtest)#vector 5 \n",
    "                    end = time.time()\n",
    "                    precision,f1score=metrics(svc.predict(pca.transform(xsubtest)),ysubtest)#precision f1score\n",
    "                    precision_scores[col3no] = precision\n",
    "                    f1_scores[col3no] = f1score\n",
    "                    elaspedt+=(end-start)\n",
    "            # get the mean -- get 1 value (cv estimate)\n",
    "                #avg CV time \n",
    "                mean_acc = acc_scores.mean()#will get nxm mean scores --> get\n",
    "                mean_precision=precision_scores.mean()\n",
    "                mean_f1= f1_scores.mean()\n",
    "\n",
    "                results[count] = [j, t, lm, mean_acc,mean_precision,mean_f1, elaspedt] #3rd col put mean(scores)\n",
    "                print('Print row ' + str(count) + ' For number = ' + str(j) + ' with T=' + str(t) \n",
    "                +' and lambda=' + str(lm) + ' avg_acc=' + str(mean_acc)+ ' av_precision=' + str(mean_precision)\n",
    "                +' avg_f1_score=' + str(mean_f1)+ ' time ' +str(elaspedt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a2705bb077fa2943766c83c4abb65d352fc3f713b0ec012bc76e8e1bb621488"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
